{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'C:/Users/Daniel/Documents/proyectos/riesgos/one year pd/chap2oneypd.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Limpieza y tratamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_arrears_12m'] = df['max_arrears_12m'].round(4)\n",
    "df['arrears_months'] = df['arrears_months'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armar una función con lambda para que haga el cambio en todas las columnas que tengan 'date' en su nombre\n",
    "from datetime import datetime\n",
    "df['origination_date2'] = pd.to_datetime(df['origination_date'])\n",
    "df['origination_date2'] = df['origination_date2'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "df['maturity_date2'] = pd.to_datetime(df['maturity_date'])\n",
    "df['maturity_date2'] = df['maturity_date2'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "df['recent_arrears_date2'] = pd.to_datetime(df['recent_arrears_date'])\n",
    "df['recent_arrears_date2'] = df['recent_arrears_date2'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Identificación de 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recent_arrears_date, months_since_2mia tienen un alto porcentaje de 'nan' por lo tanto no se consideran \n",
    "# eliminación de llos registros con nan de la variables bureau_score,num_bankrupt_iva,time_since_bankrupt,num_ccj,time_since_ccj,ccj_amount,num_bankrupt\n",
    "# num_iva,min_months_since_bankrupt\n",
    "\n",
    "df.isna().sum().to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recent_arrears_date, months_since_2mia tienen un alto porcentaje de 'nan' por lo tanto no se consideran dentro del análisis\n",
    "df2 = df.drop(['recent_arrears_date','months_since_2mia','recent_arrears_date2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminación los registros con 'nan' de la variables bureau_score,num_bankrupt_iva,time_since_bankrupt,num_ccj,time_since_ccj,ccj_amount,num_bankrupt\n",
    "# num_iva,min_months_since_bankrupt\n",
    "df2 = df2[(df2.bureau_score.notna())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminación los registros con 'nan' de la variable avg_mia_6m,max_arrears_bal_6m,max_mia_6m,avg_bal_6m,avg_bureau_score_6m \n",
    "df2 = df2[(df2.avg_bureau_score_6m.notna())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminación los registros con 'nan' de la variable region\n",
    "df2 = df2[(df2.region.notna())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validación de la no exitencia de atributos 'NaN' dentro del dataframe\n",
    "df2.isna().sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Contrucción de marca de default (tgt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['default_event'] = np.where((df2.arrears_event == 1) | (df2.bankrupt_event == 1) | (df2.term_expiry_event == 1),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.default_event.value_counts(normalize = True)*100\n",
    "# con dataframe df quitando registros con 'nan'\n",
    "# %no evento 0 = 94.742531 \n",
    "# %evento 1 = 5.257469\n",
    "# nos damos cuenta que el dataframe se sncuentr desbalanceda en la variable objetivo (evento y no evento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unidad muestral\n",
    "um   = ['id']\n",
    "# target, marca de incumplimiento\n",
    "tgt = ['default_event']\n",
    "\n",
    "# varibles continuas\n",
    "var_con= ['monthly_installment','loan_balance','bureau_score','time_since_bankrupt','time_since_ccj',\n",
    "        'ccj_amount','min_months_since_bankrupt','ltv','arrears_months'\n",
    "        ,'mob','remaining_mat','loan_term','max_arrears_12m','max_arrears_bal_6m','avg_bal_6m','avg_bureau_score_6m',\n",
    "        'cc_util','annual_income','months_since_recent_cc_delinq'\n",
    "        ]\n",
    "\n",
    "# variables categoricas\n",
    "var_cat = ['num_bankrupt_iva','num_ccj','num_bankrupt','num_iva','pl_flag','region','repayment_type','arrears_status','arrears_segment',\n",
    "           'live_status','repaid_status','month','arrears_event','bankrupt_event','term_expiry_event','worst_arrears_status','avg_mia_6m',\n",
    "           'max_mia_6m','emp_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(df,var):\n",
    "    \n",
    "    if type(var) != list:\n",
    "        var = [var]\n",
    "    \n",
    "    for v in var:\n",
    "        aux = df[v].value_counts().to_frame().rename(columns = {'count':'FA'})\n",
    "        aux['FR'] =  aux['FA'] / aux['FA'].sum()\n",
    "        aux[['FAA','FRA']] = aux.apply(np.cumsum )\n",
    "        print(f\"Frecuencias para la variable {v} \\n\")\n",
    "        display(aux)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frecuencias\n",
    "freq(df2,var_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Identificación de variables unarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se sacan las variables : \n",
    "# var_cat no aplicables\n",
    "# num_bankrupt\n",
    "# num_bankrupt_iva\n",
    "# num_iva\n",
    "# arrears_status\n",
    "# arrears_segment\n",
    "# live_status\n",
    "# repaid_status\n",
    "# month\n",
    "# arrears_event\n",
    "# bannkrupt_event\n",
    "# term_expiry_event\n",
    "# avg_mia_6m\n",
    "# max_mia_6m\n",
    "# dentro de la lista de var_cat debido a que se consideran como variables unarias, es decir; que la mayor parte de la información se concentra en \n",
    "# una categoría en particular\n",
    "\n",
    "# las nuevas variables categoricas\n",
    "var_cat = ['num_ccj','pl_flag','region','repayment_type','worst_arrears_status','emp_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq(df2,var_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Agrupación de atributos en categorías mas compactas, solo variables vategorícas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def normalizar(df,v,umbral):\n",
    "    \n",
    " #   aux = df[v].value_counts(True).to_frame().rename(columns = {'proportion': 'w'})\n",
    " #   aux[f'n_{v}'] = np.where( aux ['w'] < umbral , 'catego_peq' , aux.index )\n",
    "\n",
    "  #  moda = aux.head(1)[f'n_{v}'].values[0]\n",
    "\n",
    "#    if aux.loc[aux[f'n_{v}'] == 'catego_peq' ]['w'].sum() < umbral:\n",
    "#        aux[f'n_{v}'].replace( {'catego_peq': moda} , inplace=True)\n",
    "\n",
    " #   aux.drop('w', axis = 1, inplace = True)\n",
    "  #  #aux.reset_index(inplace=True)\n",
    "\n",
    "   # #display(aux)\n",
    "   # #return df.merge(aux,left_on = [v], right_on ='index', how ='inner').drop('index',axis = 1)\n",
    "   # return pd.merge(df,aux, left_on= [v], right_index = True, how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisar la función porque no funciona bien\n",
    "#for v in var_cat: df3 = normalizar(df2,v,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.groupby(['n_emp_length'])['n_emp_length'].count().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se sustituye la variable \"emp_lenght\" por su variable normalizda \"n_emp_lenght\"\n",
    "#var_cat = ['num_ccj','pl_flag','region','repayment_type','worst_arrears_status','n_emp_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq(df3,var_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Discretización de variables, variables continuas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de discretización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretizar(df, v, k):\n",
    "\n",
    "    kb = KBinsDiscretizer( n_bins = k , encode ='ordinal', strategy = 'quantile')\n",
    "    kb.fit(df[[v]])\n",
    "    df[f'd_{v}_{k}'] = pd.cut( df[v] , bins = kb.bin_edges_[0] , include_lowest = True ).astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in var_con: \n",
    "    for k in range(2,6): discretizar( df2 , v , k )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_con_dis = df2.filter(like ='d_').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(var_con_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_con_dis.pop(0)\n",
    "#list(var_con_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cat = var_cat + var_con_dis\n",
    "list(var_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 Partición de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación del split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df2[var_cat + var_con + tgt +['id']].copy()\n",
    "#Y = df2[tgt + ['id']].copy()\n",
    "Y = df2[tgt].copy()\n",
    "\n",
    "Xt, Xv, Yt, Yv = train_test_split(X, Y, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt.shape, Xv.shape, Yt.shape[0], Yv.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 Análisis Univariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Information Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calculo_iv( df, v, tgt ):\n",
    "#    aux = df.pivot_table( index = v, \n",
    "#                         columns= tgt, \n",
    "#                         values = um[0], \n",
    "#                         aggfunc= 'count', \n",
    "#                         fill_value=0 )\n",
    "\n",
    "#    aux[list( range(2) ) ] = aux/aux.apply(np.sum)\n",
    "\n",
    "#    aux['w'] = np.log( aux[0] / aux[1] )\n",
    "#    aux['iv'] = (aux[0] - aux[1]) * aux['w']\n",
    "\n",
    "#    return v, aux['iv'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install optbinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbinning import BinningProcess, OptimalBinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting IV value for numerical variables \n",
    "iv_list_con = []\n",
    "\n",
    "for val in var_con:\n",
    "\n",
    "    x = Xt[val].values\n",
    "    y = Xt['default_event'].values\n",
    "    optb = OptimalBinning(name = val, dtype = 'numerical', solver = 'cp')\n",
    "    optb.fit(x, y)\n",
    "    binning_table = optb.binning_table\n",
    "    iv_list_con.append(binning_table.build().loc['Totals', 'IV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting IV value for categorical variables \n",
    "iv_list_cat = []\n",
    "\n",
    "for val in var_cat:\n",
    "\n",
    "    x2 = Xt[val].values\n",
    "    y2 = Xt['default_event'].values\n",
    "    optb2 = OptimalBinning(name = val, dtype = 'categorical', solver = 'cp')\n",
    "    optb2.fit(x2, y2)\n",
    "    binning_table2 = optb2.binning_table\n",
    "    iv_list_cat.append(binning_table2.build().loc['Totals', 'IV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optb.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optb2.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_dict = {'Variable': var_con, 'IV': iv_list_con}\n",
    "iv_df_con = pd.DataFrame.from_dict(iv_dict)\n",
    "iv_df_con = iv_df_con.sort_values(by = 'IV', ascending=False)\n",
    "iv_df_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_dict2 = {'Variable': var_cat, 'IV': iv_list_cat}\n",
    "iv_df_cat = pd.DataFrame.from_dict(iv_dict2)\n",
    "iv_df_cat = iv_df_cat.sort_values(by = 'IV', ascending=False)\n",
    "iv_df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Identificación de mejores variables predictivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df_con['rankeo'] = iv_df_con.apply(lambda x: 0 if x['IV'] == 0 or x['IV'] == -1\n",
    "                                else 1 if x['IV'] > 0 and x['IV'] <= 0.02  # 1st condition\n",
    "                                else  2 if x['IV'] > 0.02 and x['IV'] <= 0.1 # 2nd condition\n",
    "                                else 3 if x['IV'] > 0.1 and x['IV'] <= 0.3 # 3rd condition\n",
    "                                else 4 if x['IV'] > 0.3 and x['IV'] <= 0.5 # 4rd condition\n",
    "                                else 5 if x['IV'] > 0.5 # 5rd condition \n",
    "                                else np.nan,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df_cat['rankeo'] = iv_df_cat.apply(lambda x: 0 if x['IV'] == 0 or x['IV'] == -1\n",
    "                                else 1 if x['IV'] > 0 and x['IV'] <= 0.02  # 1st condition\n",
    "                                else  2 if x['IV'] > 0.02 and x['IV'] <= 0.1 # 2nd condition\n",
    "                                else 3 if x['IV'] > 0.1 and x['IV'] <= 0.3 # 3rd condition\n",
    "                                else 4 if x['IV'] > 0.3 and x['IV'] <= 0.5 # 4rd condition\n",
    "                                else 5 if x['IV'] > 0.5 # 5rd condition \n",
    "                                else np.nan,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df_con.loc[(iv_df_con['rankeo'] == 3) | (iv_df_con['rankeo'] == 4)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df_con['id'] = iv_df_con.apply(lambda x: 0 if x['rankeo'] < 3 or x['rankeo'] == 5 else 1, axis = 1)\n",
    "iv_df_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df_cat = iv_df_cat.loc[(iv_df_cat['rankeo'] == 3) | (iv_df_cat['rankeo'] == 4)].reset_index(drop = True)\n",
    "iv_df_cat['raiz'] = iv_df_cat['Variable'].map( lambda x: '_'.join(x.split('_')[1:2] ) )\n",
    "iv_df_cat = iv_df_cat.sort_values(by = ['raiz','IV'],ascending = [1,0]).reset_index(drop = True)\n",
    "iv_df_cat['id'] = iv_df_cat.groupby('raiz').cumcount() + 1\n",
    "iv_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df_con2 = iv_df_con.loc[iv_df_con.id == 1]\n",
    "iv_df_con2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df_cat2 = iv_df_cat.loc[iv_df_cat.id == 1]\n",
    "iv_df_cat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Mejores variables predictivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_var_con = iv_df_con2['Variable'].tolist()\n",
    "best_var_cat = iv_df_cat2['Variable'].tolist()\n",
    "best_var = best_var_con + best_var_cat \n",
    "len(best_var) , best_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Segunda partición de los datos tomando en cuenta la mejores variables predictivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_final = Xt[best_var].copy()\n",
    "Xv_final = Xv[best_var].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_final.shape, Xv_final.shape, Yt.shape[0], Yv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 Transformación WOE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Codificación / Diccionario / Mapa WoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_process = BinningProcess(best_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing values of variables with woe\n",
    "Xt_woe = binning_process.fit_transform(Xt_final,Yt)\n",
    "Xv_woe = binning_process.fit_transform(Xv_final,Yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def codificacion_woe(df, v, tgt):\n",
    "#    aux = df.pivot_table( index=v,\n",
    "#                          columns=tgt,\n",
    "#                          values=um[0],\n",
    "#                          aggfunc='count',\n",
    "#                          fill_value=0)\n",
    "\n",
    "#    aux[list( range(2) )] = aux / aux.apply(np.sum)\n",
    "\n",
    "#    aux['w'] = np.log( aux[0] / aux[1] )\n",
    "\n",
    "#    aux.drop(range(2) , axis=1 , inplace=True )\n",
    "\n",
    "#    aux = aux.to_dict()['w']\n",
    "    \n",
    "#    return v, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_woe = list( map(  lambda v: codificacion_woe( Xt , v , tgt  ) , best_var  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, mapa in mapa_woe:\n",
    "    Xt[f'w_{v}'] = Xt[v].replace(mapa)\n",
    "    Xv[f'w_{v}'] = Xv[v].replace(mapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xt.shape, Xv.shape, Yt.shape[0], Yv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_woe = Xt.filter(like='w_').columns.tolist()\n",
    "var_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt[var_woe].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_d_avg_bureau_score_6m_2 sale de la lista de variables debido a la alta correlacion con la variable\n",
    "# w_d_avg_bureau_score_2 \n",
    "del var_woe[7]\n",
    "var_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se encontraron dos valores con valor infinito, se eliminaron de \n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "Xt.loc[Xt.loc[:, 'w_num_ccj'] == np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yt.loc[Yt.loc[:, 'id'] == 6526999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yt.loc[Yt.loc[:, 'id'] == 1041048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se indentificaron que son los registros  con id '6526999','1041048' y se eliminan de Xt\n",
    "Xt.drop(Xt[Xt['id'] == 6526999].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se indentificaron que son los registros '6526999','1041048' y se eliminan de la Xt\n",
    "Xt.drop(Xt[Xt['id'] == 1041048].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se indentificaron que son los registros '6526999','1041048' y se eliminan de la target\n",
    "Yt.drop(Yt[Yt['id'] == 6526999].index, inplace = True)\n",
    "Yt.drop(Yt[Yt['id'] == 1041048].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad1 = Xt[um + var_woe].merge(Yt , on = um , how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad1 = Xt[um + var_woe].merge(Yt , on = um , how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_reg_log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_reg_log.fit( Xt[var_woe] , Yt[tgt] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_reg_log.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_reg_log.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv.loc[Xv.loc[:, 'w_num_ccj'] == np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yv.loc[Yv.loc[:, 'id'] == 2610320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yv.drop(Yv[Yv['id'] == 2610320].index, inplace = True)\n",
    "Xv.drop(Xv[Xv['id'] == 2610320].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(m_reg_log.predict_proba(Xv[var_woe]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(m_reg_log.predict(Xv[var_woe])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yv[tgt].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_v = m_reg_log.predict(Xv[var_woe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique , counts = np.unique( rest_v , return_counts=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip( unique , counts  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikitplot.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve( y_true = Yt[tgt] , y_probas = m_reg_log.predict_proba( Xt[var_woe] ) , curves = 'macro' )\n",
    "plot_roc_curve( y_true = Yv[tgt] , y_probas = m_reg_log.predict_proba( Xv[var_woe] ) , curves = 'macro' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(model,Xt,Xv,yt,yv):\n",
    "    print(\" Métricas para modelo de clasificación: \\n\")\n",
    "\n",
    "    print(\" Valor ROC train : %.3f\"   %roc_auc_score( y_score = model.predict_proba(Xt)[:,1] , y_true = yt  )   )\n",
    "\n",
    "    print(\" Valor ROC validate : %.3f\"   %roc_auc_score( y_score = model.predict_proba(Xv)[:,1] , y_true = yv  )   )\n",
    "\n",
    "    print(\" Valor ACC : %.3f\\n\" %accuracy_score( y_pred = model.predict(Xv) , y_true = yv) )\n",
    "\n",
    "    print(\" Matriz de confusión: \", \"\\n\", confusion_matrix(y_pred = model.predict(Xv) , y_true = yv ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas( m_reg_log,Xt[var_woe] ,Xv[var_woe], Yt[tgt], Yv[tgt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDO = 30\n",
    "base_score = 700\n",
    "base_odds = 2\n",
    "\n",
    "factor = PDO / np.log(2)\n",
    "\n",
    "offset = base_score - factor * np.log(base_odds)\n",
    "\n",
    "print(factor, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = m_reg_log.coef_[0].tolist()\n",
    "beta0 = m_reg_log.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas , beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(betas)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, beta in zip( var_woe , betas ):\n",
    "    print(v, beta)\n",
    "    \n",
    "    Xt[f'p_{v}'] = np.ceil( (-Xt[v] * beta + beta0/ n ) * factor + offset / n )\n",
    "    Xv[f'p_{v}'] = np.ceil( (-Xv[v] * beta + beta0/ n ) * factor + offset / n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_puntos = [c for c in Xv.columns.tolist() if c[:2] == 'p_']\n",
    "var_puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt['score'] = Xt[var_puntos].sum(axis=1)\n",
    "Xv['score'] = Xv[var_puntos].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Xt['score'], hist = True)\n",
    "sns.distplot(Xv['score'], hist = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_prob = rest_v[:,1]\n",
    "rest_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(Yv[tgt], rest_v)\n",
    "prd = PrecisionRecallDisplay(precision, recall)\n",
    "prd.plot()\n",
    "#Yv[tgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a mano\n",
    "# precision\n",
    "# 0.952052\n",
    "# recall\n",
    "# 0.994603\n",
    "\n",
    "# A model with high precision and recall will return very few results, but most of the predictions are correct.\n",
    "# However, a model with low precision and high recall return many results, but most of the predictions will be incorrect. \n",
    "# An Ideal model will have high precision and high recall and will return many results with all correctly predicted, \n",
    "# while a baseline model will have very low precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curva de precision and recall\n",
    "# cómo saber si los datos están desbalanceados?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
